{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods. Exercises\n",
    "\n",
    "\n",
    "In this section we have only one exercise:\n",
    "\n",
    "1. Find the best three classifier in the stacking method using the classifiers from scikit-learn package, such as:\n",
    "\n",
    "\n",
    "* Linear regression,\n",
    "* Nearest Neighbors,\n",
    "* Linear SVM,\n",
    "* Decision Tree,\n",
    "* Naive Bayes,\n",
    "* QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_set\n",
    "%store -r labels\n",
    "%store -r test_data_set\n",
    "%store -r test_labels\n",
    "%store -r unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Find the best three classifier in the stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifiers():\n",
    "    \n",
    "    # fill this part\n",
    "\n",
    "    classifiers = []\n",
    "    \n",
    "    neighbors = KNeighborsClassifier()\n",
    "    neighbors.fit(data_set, labels)\n",
    "\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(data_set, labels)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(data_set, labels)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(data_set, labels)\n",
    "    \n",
    "    gaussianNB = GaussianNB()\n",
    "    gaussianNB.fit(data_set, labels)\n",
    "    \n",
    "    classifiers.append(neighbors)\n",
    "    classifiers.append(linear_regression)\n",
    "    classifiers.append(qda)\n",
    "    classifiers.append(svc)\n",
    "    classifiers.append(gaussianNB)\n",
    "    \n",
    "    return classifiers # and here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_classifiers():\n",
    "    \n",
    "    # fill this part\n",
    "\n",
    "    classifiers = []\n",
    "    \n",
    "    neighbors = KNeighborsClassifier()\n",
    "    neighbors.fit(data_set, labels)\n",
    "\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(data_set, labels)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(data_set, labels)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(data_set, labels)\n",
    "    \n",
    "    gaussianNB = GaussianNB()\n",
    "    gaussianNB.fit(data_set, labels)\n",
    "    \n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(data_set, labels)\n",
    "    \n",
    "    classifiers.append(neighbors)\n",
    "    classifiers.append(linear_regression)\n",
    "    classifiers.append(qda)\n",
    "    classifiers.append(svc)\n",
    "    classifiers.append(gaussianNB)\n",
    "    classifiers.append(tree)\n",
    "    \n",
    "    return classifiers # and here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_classifier(classifiers):\n",
    "    output = []\n",
    "    for classifier in classifiers:\n",
    "        output.append(classifier.predict(data_set))\n",
    "    output = np.array(output).reshape((130,3))\n",
    "    \n",
    "    # stacked classifier part:\n",
    "    stacked_classifier = DecisionTreeClassifier() # set here\n",
    "    stacked_classifier.fit(output.reshape((130,3)), labels.reshape((130,)))\n",
    "    test_set = []\n",
    "    for classifier in classifiers:\n",
    "        test_set.append(classifier.predict(test_data_set))\n",
    "    test_set = np.array(test_set).reshape((len(test_set[0]),3))\n",
    "    predicted = stacked_classifier.predict(test_set)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 [(0, 1, 2), (0, 1, 3), (0, 1, 4), (0, 1, 5), (0, 2, 3), (0, 2, 4), (0, 2, 5), (0, 3, 4), (0, 3, 5), (0, 4, 5), (1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3, 5), (2, 4, 5), (3, 4, 5)]\n",
      "(0.9, (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "all_classifiers = get_all_classifiers()\n",
    "combinations = list(itertools.combinations(range(len(all_classifiers)), 3))\n",
    "print(len(combinations), combinations)\n",
    "\n",
    "def make_classifier(id):\n",
    "    \n",
    "    if id == 0:\n",
    "        neighbors = KNeighborsClassifier()\n",
    "        neighbors.fit(data_set, labels)\n",
    "        return neighbors\n",
    "\n",
    "    if id == 1:\n",
    "        linear_regression = LinearRegression()\n",
    "        linear_regression.fit(data_set, labels)\n",
    "        return linear_regression\n",
    "\n",
    "    if id == 2:\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        qda.fit(data_set, labels)\n",
    "        return qda\n",
    "\n",
    "    if id == 3:\n",
    "        svc = SVC()\n",
    "        svc.fit(data_set, labels)\n",
    "        return svc\n",
    "    \n",
    "    if id == 4:\n",
    "        gaussianNB = GaussianNB()\n",
    "        gaussianNB.fit(data_set, labels)\n",
    "        return gaussianNB\n",
    "    \n",
    "    if id == 5:\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(data_set, labels)\n",
    "        return tree\n",
    "    \n",
    "\n",
    "combinations = [ (make_classifier(x[0]), make_classifier(x[1]), make_classifier(x[2])) for x in combinations ]\n",
    "\n",
    "results = []\n",
    "\n",
    "for combination in combinations:\n",
    "    predicted = build_stacked_classifier(combination)\n",
    "    accuracy = accuracy_score(test_labels, predicted)\n",
    "    results.append((accuracy, combination))\n",
    "\n",
    "max_val = max(results, key = lambda tup : tup[0])\n",
    "bests = [(x, cl) for i, (x,cl) in enumerate(results) if x == max_val[0]]\n",
    "\n",
    "# print(bests)\n",
    "for best in bests:\n",
    "    print(best)\n",
    "    \n",
    "\n",
    "# classifiers = build_classifiers()\n",
    "# predicted = build_stacked_classifier(classifiers)\n",
    "# accuracy = accuracy_score(test_labels, predicted)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
